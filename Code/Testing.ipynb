{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOOcu8YxOGMi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8632a270-9a6c-45ae-fa5f-38b5c247ac8f"
      },
      "source": [
        "#If using Google Colab, installs dependencies\n",
        "!pip -q install pybaseball\n",
        "!pip -q install MLB-StatsAPI\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 71 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 415 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 291 kB 43.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 856 kB 39.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppEGB-rC_afI"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/BeatingTheStreak/2022Finalized')\n",
        "import BaeBall as bb\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"error\")\n",
        "import numpy.random\n",
        "import statsapi\n",
        "import os\n",
        "import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uw6c-kaP3PWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dates for testing \n",
        "startdate=datetime.date(2022,4,7) \n",
        "enddate=datetime.date(2022,8,9)\n",
        "day=startdate\n",
        "\n",
        "DoubleThresh=0 #Threshhold at which we will \"double up\" batters \n",
        "#if model probabilities are below this threshhold, we will only take the top prediction\n",
        "#set at 0 because I think it's always best to double up... Can be tested/theoretically proven. \n",
        "\n",
        "\n",
        "#Read our big training data sheets. See \"train_data_generator.ipynb\"\n",
        "MatchupTrainData=pd.read_csv('/content/drive/MyDrive/BeatingTheStreak/NewFinalizedTraining/FinalizedTrainingData_UpdatedMatchup.csv')\n",
        "NoMatchupTrainData=pd.read_csv('/content/drive/MyDrive/BeatingTheStreak/NewFinalizedTraining/FinalizedTrainingData_NoMatchup.csv')\n",
        "\n",
        "\n",
        "MatchupCols=['AVG', 'OBP', 'SLG',\n",
        "       'Contact% (pi)', 'Home', 'MatchupAverage',\n",
        "       'BallparkNumber', 'era', 'h9', 'k9', 'whip', 'avg',\n",
        "        'Game 1', 'Game 2', 'Game 3', 'Game 4', 'Game 5',]\n",
        "NoMatchupCols=['AVG', 'OBP', 'SLG',\n",
        "       'Contact% (pi)', 'Home', \n",
        "       'BallparkNumber', 'era', 'h9', 'k9', 'whip', 'avg',\n",
        "        'Game 1', 'Game 2', 'Game 3', 'Game 4', 'Game 5',]\n",
        "\n",
        "#Scaling our data. Also only using columns with features we're interested in.\n",
        "SelectedMatchup=MatchupTrainData[MatchupCols]\n",
        "SelectedNoMatchup=NoMatchupTrainData[NoMatchupCols]\n",
        "Scaler=MinMaxScaler()\n",
        "ScaledSelectedMatchup=pd.DataFrame(Scaler.fit_transform(SelectedMatchup),columns=MatchupCols)\n",
        "Scaler=MinMaxScaler()\n",
        "ScaledSelectedNoMatchup=pd.DataFrame(Scaler.fit_transform(SelectedNoMatchup),columns=NoMatchupCols)\n",
        "\n",
        "#Training our models using the training data. \n",
        "#One model is trained only on batters and hitters that have previous matchups against one another, the other is trained without considering matchup data\n",
        "#This is because it is not universal for there to be a previous matchup between batter and pitcher.\n",
        "Matchup_Model=LogisticRegression(solver='saga',max_iter=4000,random_state=12)\n",
        "TrainedMatchupModel=Matchup_Model.fit(ScaledSelectedMatchup,MatchupTrainData['TestLabels'])\n",
        "NoMatchup_Model=LogisticRegression(solver='saga',max_iter=4000,random_state=12)\n",
        "TrainedNoMatchupModel=NoMatchup_Model.fit(ScaledSelectedNoMatchup,NoMatchupTrainData['TestLabels'])\n",
        "\n",
        "#Setting variables to record streaks. \"BestOf\" referes to a basic ensembling approach\n",
        "#in which we take the highest two probabilities generated by both the matchup and nomatchup models. \n",
        "CurrentBestof=0\n",
        "CurrentMatchupStreak=0\n",
        "CurrentNoMatchupStreak=0\n",
        "\n",
        "#Setting the best recorded streak variables\n",
        "BestOfBest=0\n",
        "MatchupBest=0\n",
        "NoMatchupBest=0\n",
        "\n",
        "#Creating dataframes that will store information regarding model predictions\n",
        "MatchupResults=pd.DataFrame()\n",
        "NoMatchupResults=pd.DataFrame()\n",
        "BestOfResults=pd.DataFrame()\n",
        "\n",
        "#Folders where we will save data sheets for each date tested\n",
        "MatchupFeatSheetDir='/content/drive/MyDrive/BeatingTheStreak/FeatSheetsFor2022Season/Matchup'\n",
        "NoMatchupFeatSheetDir='/content/drive/MyDrive/BeatingTheStreak/FeatSheetsFor2022Season/NoMatchup'\n",
        "\n",
        "\n",
        "while day<enddate:\n",
        "  \n",
        "  #Get MLB schedule for the given date. If it's empty, continue.\n",
        "  CurrentSched=statsapi.schedule(date=str(day))\n",
        "  if len(CurrentSched)==0:\n",
        "    day=day+datetime.timedelta(days=1)\n",
        "    continue\n",
        "\n",
        "\n",
        "  #Read the existing feature sheets if we've created them before.\n",
        "  #This saves a lot of time rather than regather all the data from every source.\n",
        "  if os.path.exists(os.path.join(MatchupFeatSheetDir,str(day)+'__Matchup.csv')) and os.path.exists(os.path.join(NoMatchupFeatSheetDir,str(day)+'__NoMatchup.csv')):\n",
        "    MatchupTestData=pd.read_csv(os.path.join(MatchupFeatSheetDir,str(day)+'__Matchup.csv'))\n",
        "    NoMatchupTestData=pd.read_csv(os.path.join(NoMatchupFeatSheetDir,str(day)+'__NoMatchup.csv'))\n",
        "  else:  \n",
        "    try: #Rare for errors to be thrown here, but sometimes exhibition matches can mess with things, etc. Will improve this in the future. \n",
        "      MatchupTestData,_,_=bb.get_feature_matrix(number_of_batters=200,date=str(day),\n",
        "                                                number_of_games=5,GetMatchupValues=1)\n",
        "      NoMatchupTestData,_,_=bb.get_feature_matrix(number_of_batters=200,date=str(day),\n",
        "                                                  number_of_games=5,GetMatchupValues=0)\n",
        "      \n",
        "\n",
        "      #Saving our feature matrices so we do not need to regenerate on subsequent runs.\n",
        "      MatchupTestData.to_csv(os.path.join(MatchupFeatSheetDir,str(day)+'__Matchup.csv'))\n",
        "      NoMatchupTestData.to_csv(os.path.join(NoMatchupFeatSheetDir,str(day)+'__NoMatchup.csv'))\n",
        "  \n",
        "    except:\n",
        "      day=day+datetime.timedelta(days=1)\n",
        "      continue\n",
        "  if len(MatchupTestData)==0: #Can occur in rare cases for various reasons. Will need to improve reporting of why\n",
        "    day=day+datetime.timedelta(days=1)\n",
        "    continue\n",
        "  #Scaling data\n",
        "  Scaler=MinMaxScaler()\n",
        "  ScaledMatchupTestData=pd.DataFrame(Scaler.fit_transform(MatchupTestData[MatchupCols]),columns=MatchupCols)\n",
        "  Scaler=MinMaxScaler()\n",
        "  ScaledNoMatchupTestData=pd.DataFrame(Scaler.fit_transform(NoMatchupTestData[NoMatchupCols]),columns=NoMatchupCols)\n",
        "\n",
        "  #Predicting and storing predictions\n",
        "  MatchupProbs=TrainedMatchupModel.predict_proba(ScaledMatchupTestData)[:,1]\n",
        "  NoMatchupProbs=TrainedNoMatchupModel.predict_proba(ScaledNoMatchupTestData)[:,1]\n",
        "\n",
        "  MatchupDF=pd.DataFrame()\n",
        "  MatchupDF['Players']=MatchupTestData.Name.values\n",
        "  MatchupDF['Probabilities']=MatchupProbs\n",
        "  MatchupDF['GroundTruths']=MatchupTestData.TestLabels.values\n",
        "  MatchupDF=MatchupDF.sort_values(by='Probabilities',ascending=False)\n",
        "\n",
        "  NoMatchupDF=pd.DataFrame()\n",
        "  NoMatchupDF['Players']=NoMatchupTestData.Name.values\n",
        "  NoMatchupDF['Probabilities']=NoMatchupProbs\n",
        "  NoMatchupDF['GroundTruths']=NoMatchupTestData.TestLabels.values\n",
        "  NoMatchupDF=NoMatchupDF.sort_values(by='Probabilities',ascending=False)\n",
        "\n",
        "  #Code for tracking streaks. \n",
        "  if MatchupDF.iloc[0,2]:\n",
        "    CurrentMatchupStreak+=1\n",
        "      #Checks if the probability for our second guess is greater than the threshhold set.\n",
        "    if MatchupDF.iloc[1,1]>DoubleThresh: \n",
        "\n",
        "      if MatchupDF.iloc[1,2]:\n",
        "        CurrentMatchupStreak+=1\n",
        "        \n",
        "      else:\n",
        "        CurrentMatchupStreak=0\n",
        "      \n",
        "    if CurrentMatchupStreak>MatchupBest:\n",
        "      MatchupBest=CurrentMatchupStreak\n",
        "  else:\n",
        "    CurrentMatchupStreak=0\n",
        "  TempMatchupResult=MatchupDF.iloc[0,:].copy().to_frame().T\n",
        "  TempMatchupResult['Date']=str(day)\n",
        "  TempMatchupResult.insert(0, 'Date', TempMatchupResult.pop('Date'))\n",
        "  TempMatchupResult['Streak']=CurrentMatchupStreak\n",
        "  MatchupResults=pd.concat((MatchupResults,TempMatchupResult),axis='rows',ignore_index=True)\n",
        "  if MatchupDF.iloc[1,1]>DoubleThresh:\n",
        "    TempMatchupResult=MatchupDF.iloc[1,:].copy().to_frame().T\n",
        "    TempMatchupResult['Date']=str(day)\n",
        "    TempMatchupResult.insert(0, 'Date', TempMatchupResult.pop('Date'))\n",
        "    TempMatchupResult['Streak']=CurrentMatchupStreak\n",
        "    MatchupResults=pd.concat((MatchupResults,TempMatchupResult),axis='rows',ignore_index=True)\n",
        "\n",
        "    \n",
        "  if NoMatchupDF.iloc[0,2]:\n",
        "    CurrentNoMatchupStreak+=1\n",
        "    if NoMatchupDF.iloc[1,1]>DoubleThresh:\n",
        "      if NoMatchupDF.iloc[1,2]:\n",
        "        CurrentNoMatchupStreak+=1\n",
        "      else:\n",
        "        CurrentNoMatchupStreak=0\n",
        "    if CurrentNoMatchupStreak>NoMatchupBest:\n",
        "      NoMatchupBest=CurrentNoMatchupStreak\n",
        "    \n",
        "  else:\n",
        "    CurrentNoMatchupStreak=0\n",
        "  TempNoMatchupResult=NoMatchupDF.iloc[0,:].copy().to_frame().T  \n",
        "  TempNoMatchupResult['Date']=str(day)\n",
        "  TempNoMatchupResult.insert(0, 'Date', TempNoMatchupResult.pop('Date'))\n",
        "  TempNoMatchupResult['Streak']=CurrentNoMatchupStreak\n",
        "  NoMatchupResults=pd.concat((NoMatchupResults,TempNoMatchupResult),axis='rows',ignore_index=True)\n",
        "\n",
        "  if MatchupDF.iloc[1,1]>DoubleThresh:\n",
        "  \n",
        "    TempNoMatchupResult=NoMatchupDF.iloc[1,:].copy().to_frame().T  \n",
        "    TempNoMatchupResult['Date']=str(day)\n",
        "    TempNoMatchupResult.insert(0, 'Date', TempNoMatchupResult.pop('Date'))\n",
        "    TempNoMatchupResult['Streak']=CurrentNoMatchupStreak\n",
        "    NoMatchupResults=pd.concat((NoMatchupResults,TempNoMatchupResult),axis='rows',ignore_index=True)\n",
        "\n",
        "  CombinedDF=pd.concat((MatchupDF.iloc[0:10,:],NoMatchupDF.iloc[0:10,:]),axis=0,ignore_index=True)\n",
        "  CombinedDF=CombinedDF.sort_values(by='Probabilities',ascending=False)\n",
        "  CombinedDF.drop_duplicates(subset='Players',ignore_index=True,keep='first')\n",
        "  if CombinedDF.iloc[0,2]:\n",
        "    CurrentBestof+=1\n",
        "    if CombinedDF.iloc[1,1]>DoubleThresh:\n",
        "      if CombinedDF.iloc[1,2]:\n",
        "        CurrentBestof+=1 \n",
        "      else:\n",
        "        CurrentBestof=0\n",
        "    if CurrentBestof>BestOfBest:\n",
        "      BestOfBest=CurrentBestof\n",
        "  else:\n",
        "    CurrentBestof=0\n",
        "  TempBestOfResult=CombinedDF.iloc[0,:].copy().to_frame().T  \n",
        "  TempBestOfResult['Date']=str(day)\n",
        "  TempBestOfResult.insert(0, 'Date', TempBestOfResult.pop('Date'))\n",
        "  TempBestOfResult['Streak']=CurrentBestof\n",
        "  BestOfResults=pd.concat((BestOfResults,TempBestOfResult),axis='rows',ignore_index=True)\n",
        "\n",
        "  if CombinedDF.iloc[1,1]>DoubleThresh: \n",
        "    TempBestOfResult=CombinedDF.iloc[1,:].copy().to_frame().T  \n",
        "    TempBestOfResult['Date']=str(day)\n",
        "    TempBestOfResult.insert(0, 'Date', TempBestOfResult.pop('Date'))\n",
        "    TempBestOfResult['Streak']=CurrentBestof\n",
        "    BestOfResults=pd.concat((BestOfResults,TempBestOfResult),axis='rows',ignore_index=True)\n",
        "    \n",
        "  print(\" Date: %s \\n Current Streaks: MATCHUP = %s NO_MATCHUP = %s BEST_OF = %s \\n Best Streaks: MATCHUP = %s NO_MATCHUP = %s BEST_OF = %s \\n\" % (str(day),CurrentMatchupStreak,CurrentNoMatchupStreak,CurrentBestof,MatchupBest,NoMatchupBest,BestOfBest))\n",
        "  day=day+datetime.timedelta(days=1)"
      ],
      "metadata": {
        "id": "LHoXYesNzazO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iW1u2BVJj4ZL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}